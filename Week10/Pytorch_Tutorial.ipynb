{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week10_Pytorch Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wDRi-rjTtyBl",
        "gQ8MIpBrwXwo",
        "E1QPlaXA0zPM",
        "y7NovKCg1Pm4",
        "P7n6CM5S2jFE",
        "lvvqY92CVdRK",
        "wBc1MKMKYDZm"
      ],
      "authorship_tag": "ABX9TyOzNqD+lsh/k9KGkAOz7E3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lahmuddin/Machine-Learning-after-Middle-Test/blob/main/Week10/Pytorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lahmuddin_11038104028_TK-42-G6**"
      ],
      "metadata": {
        "id": "2t6ZUYnbtQLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Learn The Basic**"
      ],
      "metadata": {
        "id": "QOmdQkCwtntT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2O8aGgzsr91",
        "outputId": "cc59ffa8-e002-41d2-eb5a-bf8aab2a1ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tensors**"
      ],
      "metadata": {
        "id": "wDRi-rjTtyBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4A8ye_4htfBi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing a Tensor"
      ],
      "metadata": {
        "id": "V0JfwJs4vERi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Directly from data\n",
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "7HAFB0ONuCWy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#From a NumPy array\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "kJ37CrJwuOZw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#From another tensor:\n",
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SUO1HBPuWcy",
        "outputId": "f27bbb9a-69e8-4900-a33f-839be50ff509"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.1924, 0.9947],\n",
            "        [0.4541, 0.7348]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#With random or constant values:\n",
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-66A2hAuc-i",
        "outputId": "de0c071e-717d-4fef-e11c-4430a9aba98d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.7069, 0.2951, 0.5529],\n",
            "        [0.7420, 0.3717, 0.9386]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attributes of a Tensor"
      ],
      "metadata": {
        "id": "eQtFpXxvvLgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqsqbsmzuf8F",
        "outputId": "f7b3cd5f-0242-4bc8-d207-b513dfd3f2c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operations on Tensors"
      ],
      "metadata": {
        "id": "1C940OBfvR8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to('cuda')\n"
      ],
      "metadata": {
        "id": "fWkqZNZ4vTMI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standard numpy-like indexing and slicing:\n",
        "tensor = torch.ones(4, 4)\n",
        "print('First row: ', tensor[0])\n",
        "print('First column: ', tensor[:, 0])\n",
        "print('Last column:', tensor[..., -1])\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcSVZwHpvWrf",
        "outputId": "c102b752-f2d5-4c2c-ff0a-6dd953479821"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row:  tensor([1., 1., 1., 1.])\n",
            "First column:  tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Joining Tensors\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy8xdq3lvZoh",
        "outputId": "55ce341e-a824-44d6-b3a0-13f6463a4f1e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Arithmetic Operations\n",
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(tensor)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96SwGDWCvd_v",
        "outputId": "3d67a251-a8b3-4eb5-cc47-f3d97a01e2f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Single-element tensors\n",
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNltKWBMvlBL",
        "outputId": "9b287d47-a3c1-4e6a-af2b-00c0afdbf927"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In-place operations\n",
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHPOaXKdvp0y",
        "outputId": "552cc6e8-6c75-49ac-d582-77d61e31b911"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bridge with NumPy"
      ],
      "metadata": {
        "id": "XIe8Yfahvwgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor to NumPy array\n",
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTgYpSUYvzRQ",
        "outputId": "cf51950f-3b48-4a15-d88a-bfa252faa3ae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change in the tensor reflects in the NumPy array.\n",
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYOfeNnDv4Zp",
        "outputId": "010a4152-dcc1-4c18-f55d-46eef6d2395a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy array to Tensor"
      ],
      "metadata": {
        "id": "NoejevA2wBhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "metadata": {
        "id": "eeFGUaRvwCsu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changes in the NumPy array reflects in the tensor.\n",
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj85vhLEwI-z",
        "outputId": "972abe22-7087-497d-b7a7-4490e5f2438a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset & Dataloaders**"
      ],
      "metadata": {
        "id": "gQ8MIpBrwXwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "6f1foPuAwiR_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Iterating and Visualizing the Dataset\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "JcGqAXyLwvYn",
        "outputId": "2d99a16c-df09-478a-fc04-6805deb966be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a Custom Dataset for your files\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "KBYDBfayw98s"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "    self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'])\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform"
      ],
      "metadata": {
        "id": "-B7B6TcDxawm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len\n",
        "def __len__(self):\n",
        "    return len(self.img_labels)"
      ],
      "metadata": {
        "id": "Hjm30a4h0Xux"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getitem\n",
        "def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "    image = read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx, 1]\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "        label = self.target_transform(label)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "zcK_6Pvf0bOH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "nWH46BJM0fe-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ob7c11u50jEr",
        "outputId": "6908d2cf-ad97-45a2-c382-f04370084c2f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transforms**\n",
        "We use transforms to perform some manipulation of the data and make it suitable for training."
      ],
      "metadata": {
        "id": "E1QPlaXA0zPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "ds = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")"
      ],
      "metadata": {
        "id": "sRTIcy_f064t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lambda Transform\n",
        "target_transform = Lambda(lambda y: torch.zeros(\n",
        "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
      ],
      "metadata": {
        "id": "II8iOEx81MCE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build Model (Neural Network)**\n",
        " A neural network is a module itself that consists of other modules (layers). This nested structure allows for building and managing complex architectures easily."
      ],
      "metadata": {
        "id": "y7NovKCg1Pm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "4fQ9eMdq1zCY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Device for Training\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZINZ6Mwz1zyf",
        "outputId": "ecc2dbd0-daa8-4793-ed19-e52775f5cc48"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Class\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "AUVryY5E154t"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print its structure\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpeNsyfm1-z1",
        "outputId": "b91e3e1f-f3a6-4b91-a8af-beb4eb379dea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7Kg9NaF2EWa",
        "outputId": "63f1a9c9-a445-48f0-a084-35bf8cb59452"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Layers\n",
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPHs6jYL2IdP",
        "outputId": "716b60a1-3832-4190-c3b5-19ba3d10c87f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.Flatten\n",
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCtnT-982Li6",
        "outputId": "659941f4-a90d-4e3e-883d-1edd6fb89f8d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.Linear\n",
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb07Q3Wh2QpM",
        "outputId": "53d11848-1ab2-4c10-f5cf-1ff47232303c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.ReLU\n",
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOBGrU8q2ToV",
        "outputId": "0e2255f9-b088-47a3-f7d5-785c79b5ede9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.0323, -0.5818,  0.4135, -0.5126, -0.6399, -0.4618,  0.0046, -0.2500,\n",
            "         -0.5373, -0.1008,  0.1066,  0.3562,  0.1516, -0.0986, -0.0836,  0.2448,\n",
            "          0.2050, -0.0045,  0.2844,  0.0573],\n",
            "        [-0.2738, -0.6686,  0.4016, -0.6172, -0.9247, -0.1923,  0.0342, -0.2613,\n",
            "         -0.5253, -0.2130, -0.0216,  0.3646,  0.2112, -0.2271, -0.2975,  0.3353,\n",
            "         -0.1681, -0.1371,  0.3244, -0.1098],\n",
            "        [-0.0062, -0.5442,  0.6344, -0.4849, -0.7327, -0.5043, -0.0516,  0.2048,\n",
            "         -0.4568, -0.0206,  0.1978,  0.4419,  0.1585, -0.2413, -0.1609,  0.1128,\n",
            "          0.3596, -0.2675,  0.1490,  0.0499]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.0323, 0.0000, 0.4135, 0.0000, 0.0000, 0.0000, 0.0046, 0.0000, 0.0000,\n",
            "         0.0000, 0.1066, 0.3562, 0.1516, 0.0000, 0.0000, 0.2448, 0.2050, 0.0000,\n",
            "         0.2844, 0.0573],\n",
            "        [0.0000, 0.0000, 0.4016, 0.0000, 0.0000, 0.0000, 0.0342, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.3646, 0.2112, 0.0000, 0.0000, 0.3353, 0.0000, 0.0000,\n",
            "         0.3244, 0.0000],\n",
            "        [0.0000, 0.0000, 0.6344, 0.0000, 0.0000, 0.0000, 0.0000, 0.2048, 0.0000,\n",
            "         0.0000, 0.1978, 0.4419, 0.1585, 0.0000, 0.0000, 0.1128, 0.3596, 0.0000,\n",
            "         0.1490, 0.0499]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.Sequential\n",
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ],
      "metadata": {
        "id": "29RsQ5Eh2Y8e"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.Softmax\n",
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ],
      "metadata": {
        "id": "MoZ4pvDp2bAu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Parameters\n",
        "print(\"Model structure: \", model, \"\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUyxjkSg2fek",
        "outputId": "9e3c604f-cd6a-473b-b91e-1ab56455c6a8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure:  NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0239, -0.0047,  0.0307,  ..., -0.0022,  0.0074, -0.0270],\n",
            "        [-0.0260, -0.0208,  0.0302,  ...,  0.0291, -0.0253,  0.0312]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0117,  0.0122], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0402,  0.0049,  0.0198,  ..., -0.0355,  0.0318,  0.0066],\n",
            "        [ 0.0084,  0.0361, -0.0338,  ...,  0.0176,  0.0193,  0.0025]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0312, -0.0307], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0259,  0.0134, -0.0249,  ..., -0.0410,  0.0390,  0.0047],\n",
            "        [-0.0099,  0.0327, -0.0072,  ...,  0.0301,  0.0156, -0.0084]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0420,  0.0247], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Automatic Differentiation With TORCH.AUTOGRAD**\n"
      ],
      "metadata": {
        "id": "P7n6CM5S2jFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(3)  # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "z = torch.matmul(x, w)+b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ],
      "metadata": {
        "id": "nxCWaj5_2rhz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensors, Functions and Computational graph, A function that we apply to tensors to construct computational graph is in fact an object of class Function\n",
        "print('Gradient function for z =', z.grad_fn)\n",
        "print('Gradient function for loss =', loss.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfaON-v52ujL",
        "outputId": "b410a58e-129d-4d89-9b01-13e0c7ce5721"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7f6c58acf250>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7f6c58acf290>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing Gradients\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAY6IMmbVIR3",
        "outputId": "0772a1bb-98d8-48e9-934a-651caf31f37c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1127, 0.3030, 0.3225],\n",
            "        [0.1127, 0.3030, 0.3225],\n",
            "        [0.1127, 0.3030, 0.3225],\n",
            "        [0.1127, 0.3030, 0.3225],\n",
            "        [0.1127, 0.3030, 0.3225]])\n",
            "tensor([0.1127, 0.3030, 0.3225])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Disabling Gradient Tracking\n",
        "z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf3PZUCHVP83",
        "outputId": "8885f6e6-76e7-4b6b-f04e-4e2cb3531a1e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "z_det = z.detach()\n",
        "print(z_det.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gms5PbemVWe3",
        "outputId": "4b75145b-89c3-47ab-9a40-a3026723eb72"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optimizing Model Parameters**\n",
        "Training a model is an iterative process; in each iteration (called an epoch) the model makes a guess about the output, calculates the error in its guess (loss)"
      ],
      "metadata": {
        "id": "lvvqY92CVdRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prerequisite Code\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "AlJEMJe5VXgX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "Mt0dnuDEWa6H"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "_m7oxVHGXLlh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "UMI_WSLjXd0i"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementation\n",
        "#define train_loop that loops over our optimization code, and test_loop that evaluates the model’s performance against our test data.\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "6D6BJcdNXg0I"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR9vTguRX90t",
        "outputId": "5fb6f32f-14c2-4707-b080-e49569a8d5cd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.330901  [    0/60000]\n",
            "loss: 2.304102  [ 6400/60000]\n",
            "loss: 2.284340  [12800/60000]\n",
            "loss: 2.263863  [19200/60000]\n",
            "loss: 2.263690  [25600/60000]\n",
            "loss: 2.225337  [32000/60000]\n",
            "loss: 2.237440  [38400/60000]\n",
            "loss: 2.205871  [44800/60000]\n",
            "loss: 2.203329  [51200/60000]\n",
            "loss: 2.165528  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 34.3%, Avg loss: 2.163509 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.187238  [    0/60000]\n",
            "loss: 2.170324  [ 6400/60000]\n",
            "loss: 2.110742  [12800/60000]\n",
            "loss: 2.117714  [19200/60000]\n",
            "loss: 2.088716  [25600/60000]\n",
            "loss: 2.017099  [32000/60000]\n",
            "loss: 2.048343  [38400/60000]\n",
            "loss: 1.968809  [44800/60000]\n",
            "loss: 1.975648  [51200/60000]\n",
            "loss: 1.903395  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 55.2%, Avg loss: 1.900418 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.940610  [    0/60000]\n",
            "loss: 1.908283  [ 6400/60000]\n",
            "loss: 1.784008  [12800/60000]\n",
            "loss: 1.822317  [19200/60000]\n",
            "loss: 1.745489  [25600/60000]\n",
            "loss: 1.671044  [32000/60000]\n",
            "loss: 1.700813  [38400/60000]\n",
            "loss: 1.592952  [44800/60000]\n",
            "loss: 1.624648  [51200/60000]\n",
            "loss: 1.521150  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.4%, Avg loss: 1.536016 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.604465  [    0/60000]\n",
            "loss: 1.570336  [ 6400/60000]\n",
            "loss: 1.412225  [12800/60000]\n",
            "loss: 1.487233  [19200/60000]\n",
            "loss: 1.394845  [25600/60000]\n",
            "loss: 1.363255  [32000/60000]\n",
            "loss: 1.388081  [38400/60000]\n",
            "loss: 1.301597  [44800/60000]\n",
            "loss: 1.343338  [51200/60000]\n",
            "loss: 1.246706  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.8%, Avg loss: 1.270993 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.349135  [    0/60000]\n",
            "loss: 1.331130  [ 6400/60000]\n",
            "loss: 1.159274  [12800/60000]\n",
            "loss: 1.267930  [19200/60000]\n",
            "loss: 1.156493  [25600/60000]\n",
            "loss: 1.165653  [32000/60000]\n",
            "loss: 1.196459  [38400/60000]\n",
            "loss: 1.122877  [44800/60000]\n",
            "loss: 1.164942  [51200/60000]\n",
            "loss: 1.087947  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.2%, Avg loss: 1.105267 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.178740  [    0/60000]\n",
            "loss: 1.180195  [ 6400/60000]\n",
            "loss: 0.992284  [12800/60000]\n",
            "loss: 1.129728  [19200/60000]\n",
            "loss: 1.006083  [25600/60000]\n",
            "loss: 1.031280  [32000/60000]\n",
            "loss: 1.076839  [38400/60000]\n",
            "loss: 1.007850  [44800/60000]\n",
            "loss: 1.047127  [51200/60000]\n",
            "loss: 0.987864  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.1%, Avg loss: 0.997199 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.059810  [    0/60000]\n",
            "loss: 1.081908  [ 6400/60000]\n",
            "loss: 0.876792  [12800/60000]\n",
            "loss: 1.037354  [19200/60000]\n",
            "loss: 0.909610  [25600/60000]\n",
            "loss: 0.935045  [32000/60000]\n",
            "loss: 0.997661  [38400/60000]\n",
            "loss: 0.932153  [44800/60000]\n",
            "loss: 0.964124  [51200/60000]\n",
            "loss: 0.920053  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.3%, Avg loss: 0.922951 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.971875  [    0/60000]\n",
            "loss: 1.013132  [ 6400/60000]\n",
            "loss: 0.793618  [12800/60000]\n",
            "loss: 0.971452  [19200/60000]\n",
            "loss: 0.844362  [25600/60000]\n",
            "loss: 0.863462  [32000/60000]\n",
            "loss: 0.941793  [38400/60000]\n",
            "loss: 0.881034  [44800/60000]\n",
            "loss: 0.903882  [51200/60000]\n",
            "loss: 0.870721  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.4%, Avg loss: 0.869206 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.903753  [    0/60000]\n",
            "loss: 0.961220  [ 6400/60000]\n",
            "loss: 0.731188  [12800/60000]\n",
            "loss: 0.921986  [19200/60000]\n",
            "loss: 0.797607  [25600/60000]\n",
            "loss: 0.809015  [32000/60000]\n",
            "loss: 0.899371  [38400/60000]\n",
            "loss: 0.845577  [44800/60000]\n",
            "loss: 0.858804  [51200/60000]\n",
            "loss: 0.832361  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.6%, Avg loss: 0.828465 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.849028  [    0/60000]\n",
            "loss: 0.919333  [ 6400/60000]\n",
            "loss: 0.682678  [12800/60000]\n",
            "loss: 0.883495  [19200/60000]\n",
            "loss: 0.762348  [25600/60000]\n",
            "loss: 0.767306  [32000/60000]\n",
            "loss: 0.865272  [38400/60000]\n",
            "loss: 0.819714  [44800/60000]\n",
            "loss: 0.823971  [51200/60000]\n",
            "loss: 0.801087  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.8%, Avg loss: 0.796203 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save and Load The Model**"
      ],
      "metadata": {
        "id": "wBc1MKMKYDZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "FZIg3CcWZVgU"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving and Loading Model Weights"
      ],
      "metadata": {
        "id": "EC5hSE3VZeyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "HHPZNx4xZXcl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QOtIxx8Zcj2",
        "outputId": "c1a4261d-c8ee-413f-f253-e4109c7e69f7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving and Loading Models with Shapes"
      ],
      "metadata": {
        "id": "TbswlgZhZlLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "coNtlmkhZnV-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model.pth')"
      ],
      "metadata": {
        "id": "zp_7teL6ZphE"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}